{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3d41fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "from urllib.parse import urljoin\n",
    "import logging\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, WebDriverException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# --- Cấu hình Logging ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc4ab646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Khởi tạo WebDriver --- (Giữ nguyên)\n",
    "def init_driver():\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\"); chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\"); chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--window-size=1920x1080\")\n",
    "    chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "    try:\n",
    "        service = Service(ChromeDriverManager().install())\n",
    "        driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "        logging.info(\"WebDriver đã được khởi tạo.\")\n",
    "        return driver\n",
    "    except Exception as e: logging.error(f\"Lỗi khởi tạo WebDriver: {e}\"); return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4fb1ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: get_match_report_links_selenium & get_league_season_info\n",
    "def get_match_report_links_selenium(driver, schedule_url, base_url=\"https://fbref.com\"):\n",
    "    links = []\n",
    "    if not driver: return links\n",
    "    try:\n",
    "        logging.info(f\"Đang lấy link từ: {schedule_url} bằng Selenium\")\n",
    "        driver.get(schedule_url)\n",
    "        # Tăng thời gian chờ đợi element và sleep sau đó\n",
    "        WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"table[id^='sched_'] , table.stats_table\")))\n",
    "        time.sleep(3) # Tăng sleep\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "        # ... (phần còn lại giữ nguyên) ...\n",
    "        table = soup.find('table', id=re.compile(r'^sched_.*'))\n",
    "        if not table: table = soup.find('table', class_='stats_table')\n",
    "        if not table: logging.error(f\"Không tìm thấy bảng lịch thi đấu: {schedule_url}\"); return []\n",
    "\n",
    "        match_report_cells = table.find_all('td', {'data-stat': 'match_report'})\n",
    "        for cell in match_report_cells:\n",
    "            link_tag = cell.find('a', href=True)\n",
    "            if link_tag:\n",
    "                relative_url = link_tag['href']\n",
    "                if '/en/matches/' in relative_url:\n",
    "                    full_url = urljoin(base_url, relative_url)\n",
    "                    links.append(full_url)\n",
    "        logging.info(f\"Tìm thấy {len(links)} link Match Report.\")\n",
    "        return list(dict.fromkeys(links))\n",
    "\n",
    "    except Exception as e: logging.error(f\"Lỗi lấy link từ {schedule_url}: {e}\", exc_info=False); return []\n",
    "\n",
    "def get_league_season_info(driver, schedule_url):\n",
    "    league_name, season_str = None, None\n",
    "    if not driver: return league_name, season_str\n",
    "    try:\n",
    "        logging.info(f\"Đang lấy thông tin League/Season từ: {schedule_url}\")\n",
    "        driver.get(schedule_url)\n",
    "         # Tăng thời gian chờ đợi element và sleep sau đó\n",
    "        WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"h1\")))\n",
    "        time.sleep(3) # Tăng sleep\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "        h1_tag = soup.find('h1')\n",
    "        if h1_tag:\n",
    "            # Kiểm tra lỗi Rate Limit trước khi xử lý\n",
    "            if \"Rate Limited\" in h1_tag.text:\n",
    "                logging.error(f\"Bị Rate Limit khi lấy thông tin từ {schedule_url}\")\n",
    "                return None, None\n",
    "            season_match = re.search(r'(\\d{4}-\\d{4}|\\d{4})', h1_tag.text)\n",
    "            if season_match: season_str = season_match.group(1)\n",
    "            league_name_raw = h1_tag.text\n",
    "            if season_str: league_name_raw = league_name_raw.replace(season_str, '')\n",
    "            league_name_raw = re.sub(r'Scores?.+Fixtures?', '', league_name_raw, flags=re.IGNORECASE).strip()\n",
    "            league_name = league_name_raw\n",
    "        logging.info(f\"League: {league_name}, Season: {season_str}\")\n",
    "        return league_name, season_str\n",
    "    except Exception as e: logging.error(f\"Lỗi lấy league/season từ {schedule_url}: {e}\", exc_info=False); return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b661b7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Hàm phụ: Lấy đội hình, đội hình dự bị và sơ đồ chiến thuật ---\n",
    "def get_lineup_formation_bench(soup, team_id_char, match_url):\n",
    "    starting_lineup = []; bench = []; formation = None\n",
    "    try:\n",
    "        lineup_div = soup.find('div', class_='lineup', id=team_id_char)\n",
    "        if lineup_div:\n",
    "            lineup_table = lineup_div.find('table')\n",
    "            if lineup_table:\n",
    "                header_th = lineup_table.find('th', colspan=\"2\")\n",
    "                if header_th:\n",
    "                    header_text = header_th.get_text(strip=True); formation_match = re.search(r'\\(([\\d\\-]+)\\)', header_text)\n",
    "                    if formation_match: formation = formation_match.group(1)\n",
    "\n",
    "                bench_header_row_found = None\n",
    "                bench_header_th = lineup_table.find('th', string='Bench')\n",
    "                if bench_header_th: bench_header_row_found = bench_header_th.find_parent('tr')\n",
    "\n",
    "                tbody = lineup_table.find('tbody')\n",
    "                if tbody:\n",
    "                    player_rows = tbody.find_all('tr')\n",
    "                    bench_started = False; starter_count = 0\n",
    "                    for row in player_rows:\n",
    "                        if row == bench_header_row_found: bench_started = True; continue\n",
    "                        if row.find('th') and not row.find('a', href=lambda href: href and '/players/' in href): continue\n",
    "                        player_link = row.find('a', href=lambda href: href and '/players/' in href)\n",
    "                        if player_link:\n",
    "                            player_name = player_link.text.strip()\n",
    "                            if player_name:\n",
    "                                if not bench_started and starter_count < 11: starting_lineup.append(player_name); starter_count += 1\n",
    "                                elif bench_started or starter_count >= 11: bench.append(player_name)\n",
    "                    if not bench_header_row_found and len(starting_lineup) == 11:\n",
    "                        all_player_links = lineup_table.find_all('a', href=lambda href: href and '/players/' in href)\n",
    "                        all_player_names = [link.text.strip() for link in all_player_links if link.text.strip()]\n",
    "                        if len(all_player_names) > 11: bench = all_player_names[11:]\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"[{match_url}] Lỗi khi lấy lineup/bench team '{team_id_char}': {e}\", exc_info=False) # Giảm độ chi tiết log lỗi\n",
    "    lineup_output = [formation] + starting_lineup if formation else starting_lineup\n",
    "    # Đảm bảo lineup_output là một list duy nhất để ghi vào CSV\n",
    "    lineup_str = \", \".join(filter(None, lineup_output)) # Chuyển list thành string\n",
    "    bench_str = \", \".join(filter(None, bench)) # Chuyển list thành string\n",
    "\n",
    "    # Trả về dạng string để ghi CSV dễ hơn, hoặc giữ nguyên list nếu muốn xử lý sau\n",
    "    return lineup_str, bench_str\n",
    "    # return lineup_output, bench # Nếu muốn trả về list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6c92cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Hàm phụ: Lấy tổng số liệu từ tfoot bảng Player Stats (Linh hoạt hơn) ---\n",
    "def get_totals_from_player_stats_tfoot(soup, specific_table_id, stats_to_extract, match_url):\n",
    "    \"\"\"\n",
    "    Lấy tổng các chỉ số được chỉ định từ tfoot của bảng player stats cụ thể.\n",
    "    stats_to_extract: dict dạng {'data_stat_cần_tìm': 'tên_key_trả_về'}\n",
    "                       Ví dụ: {'shots': 'shots', 'fouls': 'fouls'}\n",
    "    \"\"\"\n",
    "    # Khởi tạo totals dựa trên các key mong muốn, mặc định là 0\n",
    "    totals = {key_name: 0 for key_name in stats_to_extract.values()}\n",
    "\n",
    "    if not specific_table_id:\n",
    "        logging.warning(f\"[{match_url}] ID bảng player stats không hợp lệ: {specific_table_id}\")\n",
    "        return totals\n",
    "    try:\n",
    "        table = soup.find('table', id=specific_table_id)\n",
    "        if not table:\n",
    "            # Đôi khi bảng phụ (như passing_types) không tồn tại, không nên log là warning\n",
    "            # logging.debug(f\"[{match_url}] Không tìm thấy bảng ID: {specific_table_id}\")\n",
    "            return totals # Trả về dict mặc định nếu không tìm thấy bảng\n",
    "\n",
    "        thead = table.find('thead')\n",
    "        tfoot = table.find('tfoot')\n",
    "\n",
    "        if thead and tfoot:\n",
    "            header_row = thead.find_all('tr')[-1]\n",
    "            headers_th = header_row.find_all('th')\n",
    "            headers = [th.get('data-stat') for th in headers_th] # List các data-stat trong header\n",
    "\n",
    "            total_row = tfoot.find('tr')\n",
    "            if total_row:\n",
    "                cells = total_row.find_all(['th', 'td'])\n",
    "                # Dùng stats_to_extract thay vì stat_map cố định\n",
    "                for data_stat_name, target_key in stats_to_extract.items():\n",
    "                    try:\n",
    "                        if data_stat_name in headers:\n",
    "                            col_index = headers.index(data_stat_name)\n",
    "                            if col_index < len(cells):\n",
    "                                value_str = cells[col_index].text.strip()\n",
    "                                totals[target_key] = int(value_str) if value_str.isdigit() else 0\n",
    "                            else:\n",
    "                                logging.warning(f\"[{match_url}] Index cột '{data_stat_name}' không hợp lệ tfoot {specific_table_id}.\")\n",
    "                                # totals[target_key] đã mặc định là 0\n",
    "                        else:\n",
    "                            # Không log warning nếu header không có (ví dụ: corners trong bảng summary)\n",
    "                            # logging.debug(f\"[{match_url}] Không tìm thấy header '{data_stat_name}' trong {specific_table_id}.\")\n",
    "                            pass # totals[target_key] đã mặc định là 0\n",
    "                    except ValueError:\n",
    "                        logging.warning(f\"[{match_url}] Giá trị không hợp lệ tfoot {specific_table_id}: '{cells[col_index].text.strip()}'. Gán 0.\")\n",
    "                        totals[target_key] = 0\n",
    "                    except Exception as e_inner:\n",
    "                        logging.warning(f\"[{match_url}] Lỗi lấy tfoot {target_key} {specific_table_id}: {e_inner}\")\n",
    "                        totals[target_key] = 0\n",
    "            # else: # Không cần log nếu không có hàng tfoot\n",
    "            #    logging.debug(f\"[{match_url}] Không thấy hàng trong tfoot {specific_table_id}\")\n",
    "        # else: # Không cần log nếu không có thead/tfoot\n",
    "        #     logging.debug(f\"[{match_url}] Không thấy thead/tfoot trong {specific_table_id}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"[{match_url}] Lỗi nghiêm trọng xử lý tfoot {specific_table_id}: {e}\", exc_info=False)\n",
    "\n",
    "    return totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "034c593c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Hàm phụ: Lấy Saves từ bảng Goalkeeper Stats ---\n",
    "def get_saves_from_keeper_stats(soup, specific_div_id, match_url):\n",
    "    saves = 0\n",
    "    if not specific_div_id: return saves\n",
    "    try:\n",
    "        target_div = soup.find('div', id=specific_div_id)\n",
    "        if not target_div: logging.warning(f\"[{match_url}] Không tìm thấy div keeper stats: {specific_div_id}\"); return saves\n",
    "        keeper_table = target_div.find('table', id=re.compile(r'^keeper_stats_'))\n",
    "        if keeper_table:\n",
    "            tbody = keeper_table.find('tbody')\n",
    "            if tbody:\n",
    "                keeper_rows = tbody.find_all('tr'); total_saves = 0\n",
    "                for keeper_row in keeper_rows:\n",
    "                    saves_cell = keeper_row.find('td', {'data-stat': 'gk_saves'})\n",
    "                    if saves_cell:\n",
    "                        try: saves_val = saves_cell.text.strip(); total_saves += int(saves_val) if saves_val.isdigit() else 0\n",
    "                        except ValueError: logging.warning(f\"[{match_url}] Giá trị saves không hợp lệ {specific_div_id}: '{saves_val}'.\")\n",
    "                saves = total_saves\n",
    "    except Exception as e: logging.warning(f\"[{match_url}] Lỗi lấy saves từ {specific_div_id}: {e}\")\n",
    "    return saves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3587887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: scrape_match_data_selenium\n",
    "def scrape_match_data_selenium(driver, match_url, league_name, season_str, source_url):\n",
    "    match_data = {'match_report_url': match_url, 'league': league_name, 'season': season_str, 'source': source_url}\n",
    "    if not driver: return None\n",
    "\n",
    "    try:\n",
    "        logging.info(f\"Đang crawl: {match_url}\")\n",
    "        driver.get(match_url)\n",
    "        WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div.scorebox\")))\n",
    "        time.sleep(2) # Giữ sleep vừa phải ở đây\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "        # -- Round (Week) -- (Giữ nguyên)\n",
    "        match_data['round'] = 0\n",
    "        try:\n",
    "             header_info_div = soup.find('h1').find_next_sibling('div')\n",
    "             if header_info_div:\n",
    "                 week_text = header_info_div.text; week_match = re.search(r'\\((?:Matchweek|Round)\\s+(\\d+)\\)', week_text, re.IGNORECASE)\n",
    "                 if week_match: match_data['round'] = int(week_match.group(1))\n",
    "        except Exception: logging.warning(f\"[{match_url}] Không tìm thấy round.\")\n",
    "\n",
    "        # -- Scorebox Data -- (Giữ nguyên)\n",
    "        match_data['home'] = \"\"; match_data['away'] = \"\"; match_data['home_score'] = 0; match_data['away_score'] = 0\n",
    "        match_data['date'] = \"\"; match_data['venue'] = \"\"\n",
    "        try: # ... (code lấy scorebox) ...\n",
    "             scorebox = soup.find('div', class_='scorebox')\n",
    "             if scorebox:\n",
    "                 teams_divs = scorebox.find_all('div', recursive=False)[:2]\n",
    "                 if len(teams_divs) == 2:\n",
    "                     home_a = teams_divs[0].select_one('strong > a'); away_a = teams_divs[1].select_one('strong > a')\n",
    "                     if home_a: match_data['home'] = home_a.text.strip()\n",
    "                     if away_a: match_data['away'] = away_a.text.strip()\n",
    "                     home_score_div = teams_divs[0].select_one('div.scores > div.score'); away_score_div = teams_divs[1].select_one('div.scores > div.score')\n",
    "                     if home_score_div:\n",
    "                         try: match_data['home_score'] = int(home_score_div.text.strip())\n",
    "                         except ValueError: pass\n",
    "                     if away_score_div:\n",
    "                         try: match_data['away_score'] = int(away_score_div.text.strip())\n",
    "                         except ValueError: pass\n",
    "                 scorebox_meta = scorebox.find('div', class_='scorebox_meta')\n",
    "                 if scorebox_meta:\n",
    "                     date_tag = scorebox_meta.find('strong'); date_link = date_tag.find('a') if date_tag else None\n",
    "                     if date_link : match_data['date'] = date_link.text.strip()\n",
    "                     elif date_tag: match_data['date'] = date_tag.text.split(',')[0].strip()\n",
    "                     venue_strong = scorebox_meta.find('strong', string='Venue')\n",
    "                     if venue_strong:\n",
    "                         venue_parent = venue_strong.find_parent('div')\n",
    "                         if venue_parent:\n",
    "                             venue_small = venue_parent.find('small', string=lambda t: t and t.strip() != 'Venue')\n",
    "                             if venue_small: match_data['venue'] = venue_small.text.strip()\n",
    "                             else:\n",
    "                                 next_sibling = venue_strong.next_sibling\n",
    "                                 if next_sibling and isinstance(next_sibling, str):\n",
    "                                     venue_cleaned = next_sibling.strip(':').strip()\n",
    "                                     if venue_cleaned: match_data['venue'] = venue_cleaned\n",
    "        except Exception as e: logging.warning(f\"[{match_url}] Lỗi scorebox: {e}\", exc_info=False)\n",
    "\n",
    "\n",
    "        # -- Lineup, Formation, Bench -- (Giữ nguyên)\n",
    "        match_data['home_lineup'], match_data['home_missing'] = get_lineup_formation_bench(soup, 'a', match_url)\n",
    "        match_data['away_lineup'], match_data['away_missing'] = get_lineup_formation_bench(soup, 'b', match_url)\n",
    "\n",
    "        # -- Possession & Pass Accuracy (Cập nhật cho cấu trúc mới hơn) --\n",
    "        home_stats = {}; away_stats = {}\n",
    "        try:\n",
    "            team_stats_div = soup.find('div', id='team_stats')\n",
    "            if team_stats_div:\n",
    "                # Thử tìm theo cấu trúc <div><strong>50%</strong></div> <div>Possession</div> <div><strong>50%</strong></div>\n",
    "                possession_div = team_stats_div.find('div', string='Possession')\n",
    "                if possession_div and possession_div.parent and len(possession_div.parent.find_all('div', recursive=False)) == 3:\n",
    "                    parent_div = possession_div.parent\n",
    "                    inner_divs = parent_div.find_all('div', recursive=False)\n",
    "                    home_strong = inner_divs[0].find('strong')\n",
    "                    away_strong = inner_divs[2].find('strong')\n",
    "                    if home_strong: home_stats['Possession'] = home_strong.text.strip()\n",
    "                    if away_strong: away_stats['Possession'] = away_strong.text.strip()\n",
    "                else:\n",
    "                    # Fallback: Thử tìm cấu trúc cũ hơn (th/td trong table con hoặc hàng riêng)\n",
    "                    possession_header = team_stats_div.find('th', string='Possession')\n",
    "                    if possession_header:\n",
    "                         parent_row = possession_header.find_parent('tr')\n",
    "                         if parent_row:\n",
    "                             data_row = parent_row.find_next_sibling('tr')\n",
    "                             if data_row: # ... (logic cũ tìm trong hàng tiếp theo)\n",
    "                                 values_td = data_row.find_all('td')\n",
    "                                 if len(values_td) == 2:\n",
    "                                     home_match = re.search(r'(\\d{1,3}(?:\\.\\d+)?%)', values_td[0].get_text(strip=True)); away_match = re.search(r'(\\d{1,3}(?:\\.\\d+)?%)', values_td[1].get_text(strip=True))\n",
    "                                     if home_match: home_stats['Possession'] = home_match.group(1)\n",
    "                                     if away_match: away_stats['Possession'] = away_match.group(1)\n",
    "                             else: # ... (logic cũ tìm strong trong cùng hàng)\n",
    "                                 values_strong = parent_row.find_all('strong')\n",
    "                                 if len(values_strong) == 2:\n",
    "                                     home_match = re.search(r'(\\d{1,3}(?:\\.\\d+)?%)', values_strong[0].text); away_match = re.search(r'(\\d{1,3}(?:\\.\\d+)?%)', values_strong[1].text)\n",
    "                                     if home_match: home_stats['Possession'] = home_match.group(1)\n",
    "                                     if away_match: away_stats['Possession'] = away_match.group(1)\n",
    "\n",
    "                # Tương tự cho Passing Accuracy\n",
    "                pass_acc_div = team_stats_div.find('div', string='Passing Accuracy')\n",
    "                if pass_acc_div and pass_acc_div.parent and len(pass_acc_div.parent.find_all('div', recursive=False)) == 3:\n",
    "                     parent_div = pass_acc_div.parent\n",
    "                     inner_divs = parent_div.find_all('div', recursive=False)\n",
    "                     home_strong = inner_divs[0].find('strong')\n",
    "                     away_strong = inner_divs[2].find('strong')\n",
    "                     if home_strong: home_stats['Passing Accuracy'] = home_strong.text.strip()\n",
    "                     if away_strong: away_stats['Passing Accuracy'] = away_strong.text.strip()\n",
    "                else:\n",
    "                    pass_acc_header = team_stats_div.find('th', string='Passing Accuracy')\n",
    "                    if pass_acc_header:\n",
    "                         parent_row = pass_acc_header.find_parent('tr')\n",
    "                         if parent_row:\n",
    "                            data_row = parent_row.find_next_sibling('tr')\n",
    "                            if data_row: # ... (logic cũ)\n",
    "                                values_td = data_row.find_all('td')\n",
    "                                if len(values_td) == 2:\n",
    "                                     home_match = re.search(r'(\\d{1,3}(?:\\.\\d+)?%)', values_td[0].get_text(strip=True)); away_match = re.search(r'(\\d{1,3}(?:\\.\\d+)?%)', values_td[1].get_text(strip=True))\n",
    "                                     if home_match: home_stats['Passing Accuracy'] = home_match.group(1)\n",
    "                                     if away_match: away_stats['Passing Accuracy'] = away_match.group(1)\n",
    "                            else: # ... (logic cũ)\n",
    "                                values_strong = parent_row.find_all('strong')\n",
    "                                if len(values_strong) == 2:\n",
    "                                     home_match = re.search(r'(\\d{1,3}(?:\\.\\d+)?%)', values_strong[0].text); away_match = re.search(r'(\\d{1,3}(?:\\.\\d+)?%)', values_strong[1].text)\n",
    "                                     if home_match: home_stats['Passing Accuracy'] = home_match.group(1)\n",
    "                                     if away_match: away_stats['Passing Accuracy'] = away_match.group(1)\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"[{match_url}] Lỗi đọc #team_stats cho Possession/PassAcc: {e}\", exc_info=False)\n",
    "\n",
    "        match_data['home_possession'] = home_stats.get('Possession', '')\n",
    "        match_data['away_possession'] = away_stats.get('Possession', '')\n",
    "        match_data['home_pass_completion'] = home_stats.get('Passing Accuracy', '')\n",
    "        match_data['away_pass_completion'] = away_stats.get('Passing Accuracy', '')\n",
    "\n",
    "\n",
    "        # -- Shots, SoT, Cards, Fouls, Corners (tfoot) -- (Giữ nguyên logic từ lần sửa trước)\n",
    "        # Xác định ID các bảng Summary\n",
    "        home_summary_table_id = None; away_summary_table_id = None\n",
    "        player_summary_tables = soup.find_all('table', id=re.compile(r'^stats_.*_summary'))\n",
    "        if len(player_summary_tables) >= 1: home_summary_table_id = player_summary_tables[0].get('id')\n",
    "        if len(player_summary_tables) >= 2: away_summary_table_id = player_summary_tables[1].get('id')\n",
    "\n",
    "        # Xác định ID các bảng Passing Types\n",
    "        home_passing_types_table_id = None; away_passing_types_table_id = None\n",
    "        player_passing_types_tables = soup.find_all('table', id=re.compile(r'^stats_.*_passing_types'))\n",
    "        if len(player_passing_types_tables) >= 1: home_passing_types_table_id = player_passing_types_tables[0].get('id')\n",
    "        if len(player_passing_types_tables) >= 2: away_passing_types_table_id = player_passing_types_tables[1].get('id')\n",
    "\n",
    "        summary_stats_to_extract = { 'shots': 'shots', 'shots_on_target': 'shots_on_target', 'cards_yellow': 'yellow_cards', 'cards_red': 'red_cards', 'fouls': 'fouls' }\n",
    "        passing_types_stats_to_extract = { 'corner_kicks': 'corners' }\n",
    "\n",
    "        home_summary_totals = get_totals_from_player_stats_tfoot(soup, home_summary_table_id, summary_stats_to_extract, match_url)\n",
    "        away_summary_totals = get_totals_from_player_stats_tfoot(soup, away_summary_table_id, summary_stats_to_extract, match_url)\n",
    "        home_passing_totals = get_totals_from_player_stats_tfoot(soup, home_passing_types_table_id, passing_types_stats_to_extract, match_url)\n",
    "        away_passing_totals = get_totals_from_player_stats_tfoot(soup, away_passing_types_table_id, passing_types_stats_to_extract, match_url)\n",
    "\n",
    "        match_data['home_shots'] = home_summary_totals.get('shots', 0); match_data['away_shots'] = away_summary_totals.get('shots', 0)\n",
    "        match_data['home_shots_on_target'] = home_summary_totals.get('shots_on_target', 0); match_data['away_shots_on_target'] = away_summary_totals.get('shots_on_target', 0)\n",
    "        match_data['home_yellow_cards'] = home_summary_totals.get('yellow_cards', 0); match_data['away_yellow_cards'] = away_summary_totals.get('yellow_cards', 0)\n",
    "        match_data['home_red_cards'] = home_summary_totals.get('red_cards', 0); match_data['away_red_cards'] = away_summary_totals.get('red_cards', 0)\n",
    "        match_data['home_fouls'] = home_summary_totals.get('fouls', 0); match_data['away_fouls'] = away_summary_totals.get('fouls', 0)\n",
    "        match_data['home_corners'] = home_passing_totals.get('corners', 0); match_data['away_corners'] = away_passing_totals.get('corners', 0)\n",
    "\n",
    "        # -- Saves -- (Giữ nguyên)\n",
    "        home_keeper_div_id = None; away_keeper_div_id = None\n",
    "        keeper_stat_divs = soup.find_all('div', id=re.compile(r'^all_keeper_stats_'))\n",
    "        if len(keeper_stat_divs) >= 1: home_keeper_div_id = keeper_stat_divs[0]['id']\n",
    "        if len(keeper_stat_divs) >= 2: away_keeper_div_id = keeper_stat_divs[1]['id']\n",
    "        match_data['home_saves'] = get_saves_from_keeper_stats(soup, home_keeper_div_id, match_url)\n",
    "        match_data['away_saves'] = get_saves_from_keeper_stats(soup, away_keeper_div_id, match_url)\n",
    "\n",
    "        # --- Final Data Dict ---\n",
    "        default_numeric = 0; default_string = \"\"; default_list_str = \"\"\n",
    "        # Đảm bảo đủ 33 trường bạn cần ở đây\n",
    "        final_data_template = {\n",
    "            'date': default_string, 'home': default_string, 'away': default_string, 'home_score': default_numeric, 'away_score': default_numeric,\n",
    "            'league': default_string, 'season': default_string, 'source': default_string, 'match_report_url': default_string,\n",
    "            'round': default_numeric,\n",
    "            'venue': default_string,\n",
    "            'home_lineup': default_list_str, 'away_lineup': default_list_str, 'home_missing': default_list_str, 'away_missing': default_list_str,\n",
    "            'home_possession': default_string, 'away_possession': default_string,\n",
    "            'home_shots': default_numeric, 'away_shots': default_numeric,\n",
    "            'home_shots_on_target': default_numeric, 'away_shots_on_target': default_numeric,\n",
    "            'home_pass_completion': default_string, 'away_pass_completion': default_string,\n",
    "            'home_red_cards': default_numeric, 'away_red_cards': default_numeric,\n",
    "            'home_yellow_cards': default_numeric, 'away_yellow_cards': default_numeric,\n",
    "            'home_saves': default_numeric, 'away_saves': default_numeric,\n",
    "            'home_fouls': default_numeric, 'away_fouls': default_numeric,\n",
    "            'home_corners': default_numeric, 'away_corners': default_numeric\n",
    "        }\n",
    "        final_data = {key: match_data.get(key, default_value) for key, default_value in final_data_template.items()}\n",
    "\n",
    "        return final_data\n",
    "\n",
    "    except TimeoutException: logging.error(f\"Timeout khi tải trang: {match_url}\"); return None\n",
    "    except WebDriverException as e: logging.error(f\"Lỗi WebDriver: {match_url}: {e}\"); return None\n",
    "    except Exception as e: logging.error(f\"Lỗi không xác định: {match_url}: {e}\", exc_info=False); return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "192ac5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-08 07:55:11,391 - INFO - ====== WebDriver manager ======\n",
      "2025-05-08 07:55:11,424 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2025-05-08 07:55:11,616 - INFO - About to download new driver from https://chromedriver.storage.googleapis.com/114.0.5735.90/chromedriver_linux64.zip\n",
      "2025-05-08 07:55:12,666 - INFO - Driver downloading response is 200\n",
      "2025-05-08 07:55:18,855 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2025-05-08 07:55:19,207 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2025-05-08 07:55:19,360 - INFO - Driver has been saved in cache [/home/minh/.wdm/drivers/chromedriver/linux64/114.0.5735.90]\n",
      "2025-05-08 07:55:19,391 - ERROR - Lỗi khởi tạo WebDriver: Message: unknown error: cannot find Chrome binary\n",
      "Stacktrace:\n",
      "#0 0x56e394a9f4e3 <unknown>\n",
      "#1 0x56e3947cec76 <unknown>\n",
      "#2 0x56e3947f5757 <unknown>\n",
      "#3 0x56e3947f4029 <unknown>\n",
      "#4 0x56e394832ccc <unknown>\n",
      "#5 0x56e39483247f <unknown>\n",
      "#6 0x56e394829de3 <unknown>\n",
      "#7 0x56e3947ff2dd <unknown>\n",
      "#8 0x56e39480034e <unknown>\n",
      "#9 0x56e394a5f3e4 <unknown>\n",
      "#10 0x56e394a633d7 <unknown>\n",
      "#11 0x56e394a6db20 <unknown>\n",
      "#12 0x56e394a64023 <unknown>\n",
      "#13 0x56e394a321aa <unknown>\n",
      "#14 0x56e394a886b8 <unknown>\n",
      "#15 0x56e394a88847 <unknown>\n",
      "#16 0x56e394a98243 <unknown>\n",
      "#17 0x79961e09caa4 <unknown>\n",
      "#18 0x79961e129c3c <unknown>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Main --- (Giữ nguyên)\n",
    "if __name__ == \"__main__\":\n",
    "    schedule_page_url = \"https://fbref.com/en/comps/9/2017-2018/schedule/2017-2018-Premier-League-Scores-and-Fixtures\"\n",
    "    output_csv_file = \"fbref_premier_league_2017_2018.csv\"\n",
    "    max_retries = 2; retry_delay = 10\n",
    "\n",
    "    driver = init_driver()\n",
    "\n",
    "    if driver:\n",
    "        league_name, season_str = get_league_season_info(driver, schedule_page_url)\n",
    "        if not league_name or not season_str:\n",
    "            logging.error(\"Không lấy được League/Season. Dừng.\")\n",
    "        else:\n",
    "            match_links = get_match_report_links_selenium(driver, schedule_page_url)\n",
    "            if not match_links: logging.error(\"Không lấy được link. Dừng.\")\n",
    "            else:\n",
    "                all_matches_data = []\n",
    "                processed_links_count = 0\n",
    "                for i, link in enumerate(match_links):\n",
    "                    attempt = 0; data = None\n",
    "                    while attempt <= max_retries:\n",
    "                        data = scrape_match_data_selenium(driver, link, league_name, season_str, schedule_page_url)\n",
    "                        if data:\n",
    "                            all_matches_data.append(data)\n",
    "                            processed_links_count += 1\n",
    "                            logging.info(f\"Đã crawl thành công {processed_links_count}/{len(match_links)} links.\")\n",
    "                            break\n",
    "                        else:\n",
    "                            attempt += 1\n",
    "                            logging.warning(f\"[{link}] Lần thử {attempt}/{max_retries + 1} lỗi.\")\n",
    "                            if attempt <= max_retries: time.sleep(retry_delay)\n",
    "                            else: logging.error(f\"[{link}] Bỏ qua link sau {max_retries} lần thử lại.\")\n",
    "                    time.sleep(2) # Tạm dừng giữa các link chính"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62f6ccdd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_matches_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mall_matches_data\u001b[49m:\n\u001b[1;32m      2\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(all_matches_data)\n\u001b[1;32m      3\u001b[0m     columns_order \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhome\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maway\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhome_score\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maway_score\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleague\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseason\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mround\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvenue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhome_lineup\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maway_lineup\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhome_missing\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maway_missing\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhome_corners\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maway_corners\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatch_report_url\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     11\u001b[0m     ]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_matches_data' is not defined"
     ]
    }
   ],
   "source": [
    "if all_matches_data:\n",
    "    df = pd.DataFrame(all_matches_data)\n",
    "    columns_order = [\n",
    "        'date', 'home', 'away', 'home_score', 'away_score', 'league', 'season',\n",
    "        'round', 'venue', 'home_lineup', 'away_lineup', 'home_missing', 'away_missing',\n",
    "        'home_possession', 'away_possession', 'home_shots', 'away_shots',\n",
    "        'home_shots_on_target', 'away_shots_on_target', 'home_pass_completion', 'away_pass_completion',\n",
    "        'home_red_cards', 'away_red_cards', 'home_yellow_cards', 'away_yellow_cards',\n",
    "        'home_saves', 'away_saves', 'home_fouls', 'away_fouls',\n",
    "        'home_corners', 'away_corners', 'match_report_url', 'source'\n",
    "    ]\n",
    "    columns_to_write = [col for col in columns_order if col in df.columns]\n",
    "    df = df[columns_to_write]\n",
    "    try:\n",
    "        df.to_csv(output_csv_file, index=False, encoding='utf-8-sig')\n",
    "        logging.info(f\"Đã lưu vào: {output_csv_file}\")\n",
    "    except Exception as e: logging.error(f\"Lỗi ghi CSV: {e}\")\n",
    "else:\n",
    "    logging.info(\"Không có dữ liệu để ghi.\")\n",
    "driver.quit()\n",
    "logging.info(\"WebDriver đã đóng.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
